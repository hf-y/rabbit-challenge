{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Day 1 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 出力層"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-1 要点"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "出力層とはニューラルネットの最終層のことである. \r\n",
    "出力層の値と正解データから誤差関数を計算する. 学習とはこの誤差関数に正則化項を加えたものを損失関数とし, その小さくするように学習パラメータを更新することである. パラメータ更新の具体的な方法は次のセクションで扱う.\r\n",
    "\r\n",
    "出力層の活性化関数には, 分類問題の場合はsoftmax関数を, 回帰問題の場合を恒等関数を用いることが多い.  また, それぞれ誤差関数は, 交差エントロピーと二乗誤差が用いられる."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-2 実装演習結果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1_1_forward_propagation](exercise/1_1_forward_propagation.html)\r\n",
    "\r\n",
    "[1_1_forward_propagation_after](exercise/1_1_forward_propagation_after.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-3 考察など"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "２値分類問題で最終層の活性化関数を sigmoid 関数にすることと誤差関数を交差エントロピーにすることが整合することを確認する.\r\n",
    "\r\n",
    "学習パラメータを $w$ として最終層の出力を $p_i(w)$, 正解を$q_i$ とする. ここで $i$ はベクトルの成分の添え字である.\r\n",
    "データに関する和を省略すると, 交差エントロピーは\r\n",
    "$$\r\n",
    "E(w) = -q_0\\log{p_0(w)}-q_1\\log{p_1(w)}\r\n",
    "$$\r\n",
    "\r\n",
    "ここで $p(w)=p_1(w)$, $q=q_1$ とおくと, $p_{0}(w) = 1 - p(w)$, $q_0 = 1 - q$なので,\r\n",
    "$$\r\n",
    "E(w) = -q\\log{p(w)}-(1-q)\\log{(1-p(w))}\r\n",
    "$$\r\n",
    "\r\n",
    "今, $p(w)$が sigmoid 関数なので\r\n",
    "$$\r\n",
    "\\frac{dp}{dw} = p(1-p)\r\n",
    "$$\r\n",
    "\r\n",
    "よって $w$ で微分すると\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{array}{ll}\r\n",
    "\\frac{dE}{dw} &= \\frac{dE}{dp} \\frac{dp}{dw} \\\\\r\n",
    "&= \\left( -\\frac{q}{p} + \\frac{1-q}{1-p} \\right) p(1-p) \\\\\r\n",
    "&= -q(1-p) + (1-q)p \\\\\r\n",
    "&= p-q\r\n",
    "\\end{array}\r\n",
    "$$ \r\n",
    "\r\n",
    "したがって誤差関数の微分がゼロとなる点で $p_i = q_i \\ (i=0, 1)$ となる.\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}