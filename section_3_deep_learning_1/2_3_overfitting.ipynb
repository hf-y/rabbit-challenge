{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Day 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 過学習"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-1 要点"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "過学習とは, 訓練データでは高い性能を示していた学習モデルが, テストデータに対しては低い精度を示す現象である. \r\n",
    "\r\n",
    "過学習はニューラルネットで確率的勾配降下法を行ったときに観察される. 訓練データ, 検証データに対する損失関数を訓練損失, 検証損失と呼ぶことにしよう. 横軸にエポック数を, 縦軸に損失関数の値をとったグラフを描くと, 最初はエポック数とともに訓練損失と検証損失の両方が減少する. しかしある程度エポック数が大きくなったところから検証損失だけが上昇する. この領域で過学習が発生している.\r\n",
    "\r\n",
    "過学習を抑制する方法として講義では以下の方法が紹介された.\r\n",
    "* 損失関数に対する正則化項の導入\r\n",
    "  * weight decay\r\n",
    "    * 学習パラメータの $L^2$ ノルムを正則化項とする\r\n",
    "  * sparse 正則化\r\n",
    "    * 学習パラメータの $L^1$ ノルムを正則化項とする\r\n",
    "* dropout\r\n",
    "  * 訓練時のみ特定の層のニューロンをランダムに選んで値をゼロとする\r\n",
    "  * その層のニューロンのうちゼロにする割合をdropout rateと呼ぶ\r\n",
    "  * 推論時はdropoutしない代わりに選択確率をかけて出力を小さくする（訓練時と同等にする）\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-2 実装演習結果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[2_5_overfiting](exercise/2_5_overfiting.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-3 考察など"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "dropoutとベイズ推論との関係および信頼度を求めるという利用方法が以下で論じられている.\r\n",
    "\r\n",
    "* Yarin Gal, Zoubin Ghahramani\r\n",
    "  * Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\r\n",
    "  * [arXiv:1506.02142](https://arxiv.org/abs/1506.02142)\r\n",
    "\r\n",
    "以下で議論されているようにdropoutとバッチ正則化の相性が悪いということもあってか, 最近ではdropoutを採用している論文を見かけない.\r\n",
    "\r\n",
    "* X. Li et al.\r\n",
    "  * Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift\r\n",
    "  * [arXiv:1801.05134](https://arxiv.org/abs/1801.05134)\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}