{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. 要約"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰では説明変数にシグモイド関数\r\n",
    "$$\r\n",
    "\\mathrm{sigmoid}(x) = \\frac{1}{1+e^{-w\\cdot x}}\r\n",
    "$$\r\n",
    "を適用した値を $\\{0, 1\\}$-分類問題のクラス $1$ に属する確率とみなす.\r\n",
    "ここで指数関数の肩の上は入力データとパラメータの線形結合（内積）であり, \r\n",
    "定数項は $x$ の成分のひとつに含まれていると考えることができる.\r\n",
    "\r\n",
    "機械学習としてはシグモイド関数を学習モデルとし, 損失関数を交差エントロピーとしたものと考えることができる. 学習パラメータは $w$ である.\r\n",
    "\r\n",
    "また, 一般化線形モデルという枠組みではリンク関数が以下のロジット関数の場合に相当する.\r\n",
    "$$\r\n",
    "\\begin{equation*}\r\n",
    "\\mathrm{logit}(p) = \\ln{\\frac{p}{1-p}}\r\n",
    "\\end{equation*}\r\n",
    "$$\r\n",
    "確率ではなく分類クラスを与えたい場合は, $p=\\frac{1}{2}$ を決定境界面とすることが多い. 境界面は $w\\cdot x = 0$ なる $x$ からなる平面である."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. 実装演習実施結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/skl_logistic_regression_last.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26ba46d4ddfbbb7434ae4df4c2c95f7e59dc161bdd1bad6b7cd3d053f0e418ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('atma10': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}