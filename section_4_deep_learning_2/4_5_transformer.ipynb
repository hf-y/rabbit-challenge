{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Day 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5 Transformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TransformerはAttention機構を活用したNLPタスク向けのモデルで, その後のBertなどの成果があり, 近年最も注目されたモデルである. エンコーダ-デコーダ型のアーキテクチャだが, RNNを用いておらず, Attentionが主要な役割を果たしている. \r\n",
    "Attentionを用いた層にはSelf-Attention層とTarget-Source‐Attention層と呼ばれる２つがある.\r\n",
    "\r\n",
    "近年では画像処理への応用が研究されている（Vision Transformer）."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5-1 要点"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5-2 考察など"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "提案論文は以下の通り. タイトルが面白い.\r\n",
    "\r\n",
    "* A. Vaswani et al.\r\n",
    "  * Attention Is All You Need\r\n",
    "  * [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)\r\n",
    "\r\n",
    "Vision Transformerについては\r\n",
    "\r\n",
    "* A. Dosovitskiy et al.\r\n",
    "  * An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\r\n",
    "  * [arXiv:2010.11929](https://arxiv.org/abs/2010.11929)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}