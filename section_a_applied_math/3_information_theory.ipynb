{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 情報理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 情報量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値 $\\{x_i\\}_{i=1}^{m}$ 取る確率変数 $X$ を考える. $X=x_i$ であるとわかったときに得られる（自己）情報量 $I_i$ を次で定義する.\r\n",
    "$$\r\n",
    "I(X=x_i) = -\\log_2{P(X=x_i)}\r\n",
    "$$\r\n",
    "この定義の妥当性は次のように **議論** できる. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ と独立な確率変数 $Y$ を考える. $Y$が取りうる値を $\\{y_i\\}_{i=1}^{n}$ としよう. $X$ と $Y$ は独立であるため $X=x_i$ かつ $Y=y_j$ であるとわかったときに得られる情報量 $I(X=x_i, Y=y_i)$ は加法的, すなわち\r\n",
    "$$\r\n",
    "I(X=x_i, Y=y_i) = I(X=x_i) + I(Y=y_i)\r\n",
    "$$\r\n",
    "となるようにしたい. また, 情報量は確率の関数であるとしよう. \r\n",
    "$$\r\n",
    "I(X) = I(P(X))\r\n",
    "$$\r\n",
    "このとき上述の加法性の式は（ $x_i$ や $y_j$ を省略して）\r\n",
    "$$\r\n",
    "I(P(X, Y)) = I(P(X)) + I(P(Y))\r\n",
    "$$\r\n",
    "と書ける."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方で独立性から確率分布について\r\n",
    "$$\r\n",
    "P(X, Y) = P(X)P(Y)\r\n",
    "$$\r\n",
    "したがって\r\n",
    "$$\r\n",
    "I(P(X)P(Y)) = I(P(X)) + I(P(Y))\r\n",
    "$$\r\n",
    "これが任意の確率分布に成り立つためには, 連続変数 $x$, $y$ に対して\r\n",
    "$$\r\n",
    "I(xy) = I(x) + I(y)\r\n",
    "$$\r\n",
    "という関数等式が成立しなければいけない."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この式から, まず $x=1$, $y=1$ とおけば $I(1) = 0$ が得られる. 次に両辺を $y$ で微分して $y=1$ とおくと,\r\n",
    "$$\r\n",
    "xI^{\\prime}(x) = I^{\\prime}(1)\r\n",
    "$$\r\n",
    "この微分方程式を解くと $a$, $b$ を定数として\r\n",
    "$$\r\n",
    "I(x) = a\\log_2{x}+b\r\n",
    "$$\r\n",
    "$I(1)=0$ であったから $b=0$で\r\n",
    "$$\r\n",
    "I(x) = a\\log_2{x}\r\n",
    "$$\r\n",
    "となる.\r\n",
    "よって\r\n",
    "$$\r\n",
    "I(X) = a\\log_2{P(X)}\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も基本的なケースとして$m=2$ で $P(X=x_1)=P(X=x_2)=\\frac{1}{2}$ の場合を考える.\r\n",
    "このときの情報量を $1$ 単位と定義すると（単位はbit）,\r\n",
    "$$\r\n",
    "I(X=x_i) = a\\log_2{\\frac{1}{2}} = 1\r\n",
    "$$\r\n",
    "よって比例定数 $a$ は $-1$ であり, 冒頭の定義式が得られる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 エントロピー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均情報量 $H(X)$ を（平均）エントロピーと呼ぶ. 以降, 対数の底は常に $2$ であるとし明示しない. $p_i = P(X=x_i)$ として\r\n",
    "$$\r\n",
    "H(X) = -\\sum_{i}^{n}p_i\\log{p_i}\r\n",
    "$$\r\n",
    "である. 確率 $0 \\le p_i \\le 1$ に対して $-\\log{p_i} \\ge 0$ であるから\r\n",
    "$$\r\n",
    "H(X) \\ge 0\r\n",
    "$$\r\n",
    "である."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結合分布に対しては結合エントロピーを\r\n",
    "$$\r\n",
    "H(X, Y) = -\\sum_{x,y}{P(X=x, Y=y)}\\log{P(X=x, Y=y)}\r\n",
    "$$\r\n",
    "で定義する.\r\n",
    "また, 条件付き分布に対して条件付エントロピーを\r\n",
    "$$\r\n",
    "H(X|Y) = -\\sum_{y}{ P(Y=y) \\sum_{x}{P(X=x | Y=y)\\log{P(X=x | Y=y)}} }\r\n",
    "$$\r\n",
    "で定義する.\r\n",
    "このとき\r\n",
    "$$\r\n",
    "P(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\r\n",
    "$$\r\n",
    "であるから\r\n",
    "$$\r\n",
    "H(X|Y) = -\\sum_{x,y}{P(X=x, Y=y)\\log{P(X=x | Y=y)} }\r\n",
    "$$\r\n",
    "とも書ける."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また,\r\n",
    "$$\r\n",
    "\\begin{aligned}\r\n",
    "H(X|Y) &= -\\sum_{x,y}{P(X=x, Y=y)\\log{\\frac{P(X=x, Y=y)}{P(Y=y)}} } \\\\\r\n",
    "&= -\\sum_{x,y}{P(X=x, Y=y)(\\log{P(X=x, Y=y)} - \\log{P(Y=y)}) } \\\\\r\n",
    "&= H(X, Y) - H(Y)\r\n",
    "\\end{aligned}\r\n",
    "$$\r\n",
    "であるが, 平均エントロピーと同様に\r\n",
    "$$\r\n",
    "H(X, Y) \\ge 0\r\n",
    "$$\r\n",
    "$$\r\n",
    "H(X|Y) \\ge 0\r\n",
    "$$\r\n",
    "なので\r\n",
    "$$\r\n",
    "H(X, Y) \\ge H(Y)\r\n",
    "$$\r\n",
    "が得られる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 相互情報量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降では連続分布の表式を用いる. 確率分布 $P(X)$ と $P(Y)$ の相互情報量を\r\n",
    "$$\r\n",
    "I(P(X);P(Y)) = \\int dxdy{ P(x, y)\\log{\\frac{P(x,y)}{P(x) P(y)}} }\r\n",
    "$$\r\n",
    "で定義する.\r\n",
    "\r\n",
    "$X$ と $Y$ が独立ならば $I(P(X);P(Y)) = 0$ である.\r\n",
    "\r\n",
    "$$\r\n",
    "\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 KL-divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率分布 $P(x)$ と $Q(y)$ の違いを表す量として KL-divergence \r\n",
    "$$\r\n",
    "D(P||Q) = \\int{P\\log{\\frac{P}{O}}}dx\r\n",
    "$$\r\n",
    "を導入する.\r\n",
    "２つの分布が一致するとき$D(P||Q) = 0$ であり,\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26ba46d4ddfbbb7434ae4df4c2c95f7e59dc161bdd1bad6b7cd3d053f0e418ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('atma10': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}